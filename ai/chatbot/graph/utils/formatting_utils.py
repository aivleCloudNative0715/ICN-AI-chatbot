# formatting_utils.py - ê³µí†µ í¬ë§·íŒ… ì§€ì¹¨ ê´€ë¦¬
from chatbot.rag.config import DISCLAIMER, client

# ê³µí†µ í¬ë§·íŒ… ì§€ì¹¨ (ëª¨ë“  ì˜ë„ì—ì„œ ê³µí†µìœ¼ë¡œ ì‚¬ìš©)
COMMON_FORMATTING_SUFFIX = """

ë‹¤ìŒ ì§€ì¹¨ì„ ë°˜ë“œì‹œ ë”°ë¥´ì„¸ìš”:
1. ëª¨ë“  ì‘ë‹µì€ HTML í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ë©°, `<p>`, `<ul>`, `<li>`, `<strong>`, `<span>` íƒœê·¸ë¥¼ ì ì ˆíˆ ì‚¬ìš©í•˜ì„¸ìš”. ë§ˆí¬ë‹¤ìš´ ë¬¸ë²•ì€ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
2. ë‹µë³€ì—ì„œ **ì¤‘ìš”í•œ ì •ë³´ë‚˜ í‚¤ì›Œë“œ**ëŠ” `<strong>` íƒœê·¸ë¥¼ ì‚¬ìš©í•˜ê³ , `style="color: #1976D2;"`ë¥¼ ì ìš©í•˜ì—¬ íŒŒë€ìƒ‰ìœ¼ë¡œ ê°•ì¡°í•´ì£¼ì„¸ìš”.
3. ëª©ë¡ì„ ë‚˜ì—´í•  ë•ŒëŠ” `<ul>`ê³¼ `<li>` íƒœê·¸ë¥¼ ì‚¬ìš©í•˜ê³ , `<li>` íƒœê·¸ì—ëŠ” ìƒ‰ìƒì„ ì ìš©í•˜ì§€ ë§ˆì„¸ìš”.
4. ë‹µë³€ì˜ ì‹œì‘ ë¶€ë¶„ì— ì œëª©ì´ ìˆë‹¤ë©´, `<h3>` íƒœê·¸ë¥¼ ì‚¬ìš©í•˜ê³  `style="color: #1976D2;"`ë¥¼ ì ìš©í•˜ì—¬ ëˆˆì— ë„ê²Œ ë§Œë“¤ì–´ì£¼ì„¸ìš”.
5. ë‹µë³€ ë‚´ìš©ì— ì–´ìš¸ë¦¬ëŠ” ì´ëª¨ì§€ë¥¼ 1-2ê°œ í¬í•¨í•´ì„œ ë” ì¹œê·¼í•˜ê²Œ ë§Œë“¤ì–´ì£¼ì„¸ìš”.
6. ë¶ˆí•„ìš”í•œ ì„œë‘ëŠ” ìƒëµí•˜ê³ , ë°”ë¡œ ë‹µë³€ ë³¸ë¬¸ì„ ì‹œì‘í•˜ì„¸ìš”.
7. ê°™ì€ ì •ë³´ë¥¼ ì¤‘ë³µìœ¼ë¡œ í‘œì‹œí•˜ì§€ ë§ˆì„¸ìš”.
8. í•­ê³µí¸ ìƒíƒœ ì •ë³´ëŠ” ì ì ˆí•œ ìƒ‰ìƒìœ¼ë¡œ í‘œì‹œí•˜ì„¸ìš” (ì¶œë°œ: #E65100, ë„ì°©: #388E3C, ì§€ì—°: #D32F2F).
9. í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”.
10. ì¹œê·¼í•˜ê³  ì „ë¬¸ì ì¸ í†¤ì„ ìœ ì§€í•˜ì„¸ìš”.
"""

# ì˜ë„ë³„ ì¶”ê°€ ì§€ì¹¨ (í•„ìš”í•œ ê²½ìš°ë§Œ)
INTENT_SPECIFIC_GUIDELINES = {
    "parking": """
11. ğŸš— ì´ëª¨ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬ ì£¼ì°¨ì¥ ì •ë³´ë¥¼ í‘œì‹œí•˜ì„¸ìš”.
12. ì‚¬ìš© ê°€ëŠ¥í•œ ìë¦¬ ìˆ˜ì™€ ì´ìš©ë¥ ì„ ëª…í™•íˆ í‘œì‹œí•˜ì„¸ìš”.
13. ë‹¨ê¸°ì£¼ì°¨ì¥ê³¼ ì¥ê¸°ì£¼ì°¨ì¥ì„ êµ¬ë¶„í•˜ì—¬ í‘œì‹œí•˜ì„¸ìš”.""",

    "weather": """
11. ğŸŒ¤ï¸ ì´ëª¨ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‚ ì”¨ ì •ë³´ë¥¼ í‘œì‹œí•˜ì„¸ìš”.
12. ê¸°ì˜¨ê³¼ ë‚ ì”¨ ìƒíƒœë¥¼ ëª…í™•íˆ í‘œì‹œí•˜ì„¸ìš”.
13. ì—¬í–‰ ê´€ë ¨ ì¡°ì–¸ì´ ìˆìœ¼ë©´ í¬í•¨í•˜ì„¸ìš”.""",

    "baggage_claim_info": """
11. ğŸ§³ ì´ëª¨ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬ ìˆ˜í•˜ë¬¼ ì •ë³´ë¥¼ í‘œì‹œí•˜ì„¸ìš”.
12. ìˆ˜í•˜ë¬¼ ë²¨íŠ¸ ë²ˆí˜¸ë¥¼ `<strong>` íƒœê·¸ì™€ íŒŒë€ìƒ‰ìœ¼ë¡œ ê°•ì¡°í•˜ì„¸ìš”.
13. í„°ë¯¸ë„ë³„ë¡œ êµ¬ë¶„í•˜ì—¬ í‘œì‹œí•˜ì„¸ìš”.""",

    "complex_intent": """
11. ë³µí•© ì •ë³´ì˜ ê²½ìš° ì„¹ì…˜ë³„ë¡œ êµ¬ë¶„í•˜ì—¬ í‘œì‹œí•˜ì„¸ìš”.
12. ê´€ë ¨ëœ ëª¨ë“  ì •ë³´ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ì •ë¦¬í•˜ì„¸ìš”."""
}

def get_enhanced_prompt(original_prompt, intent_name=None):
    """
    ì›ë³¸ í”„ë¡¬í”„íŠ¸ì— í¬ë§·íŒ… ì§€ì¹¨ì„ ì¶”ê°€í•´ì„œ ì™„ì „í•œ í”„ë¡¬í”„íŠ¸ ë°˜í™˜
    
    Args:
        original_prompt (str): ê¸°ì¡´ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        intent_name (str, optional): ì˜ë„ëª… (ì¶”ê°€ ì§€ì¹¨ì´ ìˆëŠ” ê²½ìš°)
    
    Returns:
        str: í¬ë§·íŒ… ì§€ì¹¨ì´ í¬í•¨ëœ ì™„ì „í•œ í”„ë¡¬í”„íŠ¸
    """
    # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ + ê³µí†µ í¬ë§·íŒ… ì§€ì¹¨
    enhanced_prompt = original_prompt + COMMON_FORMATTING_SUFFIX
    
    # ì˜ë„ë³„ ì¶”ê°€ ì§€ì¹¨ì´ ìˆìœ¼ë©´ ì¶”ê°€
    if intent_name and intent_name in INTENT_SPECIFIC_GUIDELINES:
        enhanced_prompt += INTENT_SPECIFIC_GUIDELINES[intent_name]
    
    
    return enhanced_prompt

def get_formatted_llm_response(original_prompt, user_query, intent_name=None, temperature=0.5, max_tokens=800):
    """
    í¬ë§·íŒ… ì§€ì¹¨ì´ í¬í•¨ëœ í”„ë¡¬í”„íŠ¸ë¡œ LLMì„ í˜¸ì¶œí•˜ê³  DISCLAIMERê°€ í¬í•¨ëœ ìµœì¢… ì‘ë‹µì„ ë°˜í™˜
    
    Args:
        original_prompt (str): ê¸°ì¡´ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        user_query (str): ì‚¬ìš©ì ì§ˆë¬¸
        intent_name (str, optional): ì˜ë„ëª… (ì¶”ê°€ ì§€ì¹¨ì´ ìˆëŠ” ê²½ìš°)
        temperature (float): LLM temperature ì„¤ì •
        max_tokens (int): ìµœëŒ€ í† í° ìˆ˜
    
    Returns:
        str: DISCLAIMERê°€ í¬í•¨ëœ ìµœì¢… ì‘ë‹µ
    """
    # í¬ë§·íŒ… ì§€ì¹¨ì´ í¬í•¨ëœ í”„ë¡¬í”„íŠ¸ ìƒì„±
    enhanced_prompt = get_enhanced_prompt(original_prompt, intent_name)
    
    # LLM í˜¸ì¶œ
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": enhanced_prompt},
            {"role": "user", "content": user_query}
        ],
        temperature=temperature,
        max_tokens=max_tokens
    )
    
    final_response = response.choices[0].message.content
    
    # DISCLAIMER ì¶”ê°€ (complex_intentê°€ ì•„ë‹Œ ê²½ìš°ì—ë§Œ)
    if intent_name != "complex_intent":
        final_response += DISCLAIMER
    
    return final_response

def get_formatted_llm_response_single_message(full_prompt, intent_name=None, temperature=0.5, max_tokens=800, role="user"):
    """
    ì™„ì „í•œ í”„ë¡¬í”„íŠ¸ë¡œ LLMì„ í˜¸ì¶œí•˜ê³  DISCLAIMERê°€ í¬í•¨ëœ ìµœì¢… ì‘ë‹µì„ ë°˜í™˜ (ë‹¨ì¼ ë©”ì‹œì§€ìš©)
    
    Args:
        full_prompt (str): ì™„ì „í•œ í”„ë¡¬í”„íŠ¸ (ì´ë¯¸ formattingê³¼ user queryê°€ í¬í•¨ë¨)
        intent_name (str, optional): ì˜ë„ëª… (DISCLAIMER ì¶”ê°€ ì—¬ë¶€ ê²°ì •)
        temperature (float): LLM temperature ì„¤ì •
        max_tokens (int): ìµœëŒ€ í† í° ìˆ˜
        role (str): ë©”ì‹œì§€ ì—­í•  ("user" ë˜ëŠ” "system")
    
    Returns:
        str: DISCLAIMERê°€ í¬í•¨ëœ ìµœì¢… ì‘ë‹µ
    """
    # í¬ë§·íŒ… ì§€ì¹¨ ì¶”ê°€
    enhanced_prompt = get_enhanced_prompt(full_prompt, intent_name)
    
    # LLM í˜¸ì¶œ
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": role, "content": enhanced_prompt}
        ],
        temperature=temperature,
        max_tokens=max_tokens
    )
    
    final_response = response.choices[0].message.content
    
    # DISCLAIMER ì¶”ê°€ (complex_intentê°€ ì•„ë‹Œ ê²½ìš°ì—ë§Œ)
    if intent_name != "complex_intent":
        final_response += DISCLAIMER
    
    return final_response

