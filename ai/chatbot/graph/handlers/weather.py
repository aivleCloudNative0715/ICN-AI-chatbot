import requests
from chatbot.graph.state import ChatState
from chatbot.rag.utils import get_mongo_collection
from chatbot.rag.config import client
import json

common_disclaimer = (
            "\n\n---"
            "\nì£¼ì˜: ì´ ì •ë³´ëŠ” ì¸ì²œêµ­ì œê³µí•­ ì›¹ì‚¬ì´íŠ¸(ê³µì‹ ì¶œì²˜)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì œê³µë˜ì§€ë§Œ, ì‹¤ì œ ê³µí•­ ìš´ì˜ ì •ë³´ì™€ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            "ê°€ì¥ ì •í™•í•œ ìµœì‹  ì •ë³´ëŠ” ì¸ì²œêµ­ì œê³µí•­ ê³µì‹ ì›¹ì‚¬ì´íŠ¸ ë˜ëŠ” í•´ë‹¹ í•­ê³µì‚¬/ê¸°ê´€/ì‹œì„¤ì— ì§ì ‘ í™•ì¸í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤."
        ) 

def airport_weather_current_handler(state: ChatState) -> ChatState:
    """
    ì¸ì²œê³µí•­ ë‚ ì”¨ì— ëŒ€í•œ ì§ˆë¬¸ì´ ë“¤ì–´ì™”ì„ ë•Œ ì²˜ë¦¬í•´ì£¼ëŠ” í•¸ë“¤ëŸ¬
    """
    # ğŸ“Œ ìˆ˜ì •ëœ ë¶€ë¶„: rephrased_queryë¥¼ ë¨¼ì € í™•ì¸í•˜ê³ , ì—†ìœ¼ë©´ user_inputì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
    query_to_process = state.get("rephrased_query") or state.get("user_input", "")
    intent_name = state.get("intent", "airport_weather_current")
    
    if not query_to_process:
        print("ë””ë²„ê·¸: ì‚¬ìš©ì ì¿¼ë¦¬ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
        return {**state, "response": "ì£„ì†¡í•©ë‹ˆë‹¤. ì§ˆë¬¸ ë‚´ìš©ì„ íŒŒì•…í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”."}

    print(f"\n--- {intent_name.upper()} í•¸ë“¤ëŸ¬ ì‹¤í–‰ ---")
    print(f"ë””ë²„ê·¸: í•¸ë“¤ëŸ¬ê°€ ì²˜ë¦¬í•  ìµœì¢… ì¿¼ë¦¬ - '{query_to_process}'")
    
    try:
        collection_ATMOS = get_mongo_collection(collection_name="ATMOS")
        collection_TAF = get_mongo_collection(collection_name="TAF")
        
        atmos_documents = list(collection_ATMOS.find({}, {"_id": 0}))
        taf_documents = list(collection_TAF.find({}, {"_id": 0}))
        
    except Exception as e:
        error_msg = f"ì£„ì†¡í•©ë‹ˆë‹¤. DB ì—°ê²° ë˜ëŠ” ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
        print(f"ë””ë²„ê·¸: {error_msg}")
        return {**state, "response": error_msg}
    
    try: 
        prompt_template = (
            "ë‹¹ì‹ ì€ ì¸ì²œêµ­ì œê³µí•­ì˜ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ì¹œì ˆí•˜ê³  ìœ ìš©í•œ ì±—ë´‡ì…ë‹ˆë‹¤."
            "ë‹¹ì‹ ì€ ì¸ì²œêµ­ì œê³µí•­ì˜ ë‚ ì”¨ì— ëŒ€í•œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€ë‹µí•´ì£¼ì–´ì•¼ í•©ë‹ˆë‹¤."
            "ë‹¹ì‹ ì´ ì¶”ê°€ì ìœ¼ë¡œ ì°¸ê³ í•  ìˆ˜ ìˆëŠ” ì •ë³´ëŠ” ë‘ ê°€ì§€ì…ë‹ˆë‹¤."
            "'{atmos_documents}'ì—ì„œ tmì€ ë°ì´í„°ê°€ ì¸¡ì •ëœ ì‹œê°, l_visëŠ” ì‹œì •, taëŠ” 0.1ë„ ë‹¨ìœ„ì˜ ì„­ì”¨ ì˜¨ë„, hmì€ % ë‹¨ìœ„ì˜ ìŠµë„, rnì€ mmë‹¨ìœ„ ê°•ìˆ˜ëŸ‰, ws_10ì€ 0.1m/s ë‹¨ìœ„ì˜ 10ë¶„ í‰ê·  í’ì†ì…ë‹ˆë‹¤."
            "'{taf_documents}'ëŠ” ê³µí•­ ì˜ˆë³´(TAF)ì˜ ì „ë¬¸ì…ë‹ˆë‹¤."
            "ì œê³µë°›ì€ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ê·¸ë¦¬ê³  ë‹¹ì‹ ì´ í™•ì¸ ê°€ëŠ¥í•œ ì¸ì²œê³µí•­ì˜ í˜„ ì‹œê° ë‚ ì”¨ì™€ ë‚ ì”¨ ì˜ˆë³´ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ì„œ ëŒ€ë‹µí•˜ì„¸ìš”."
        )
        
        formatted_prompt = prompt_template.format(
            atmos_documents=json.dumps(atmos_documents, ensure_ascii=False, indent=2, default=str),
            taf_documents=json.dumps(taf_documents, ensure_ascii=False, indent=2, default=str)
        )
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": formatted_prompt},
                # ğŸ“Œ ìˆ˜ì •ëœ ë¶€ë¶„: user_query ëŒ€ì‹  query_to_processë¥¼ LLMì— ì „ë‹¬í•©ë‹ˆë‹¤.
                {"role": "user", "content": query_to_process}
            ],
            temperature=0.5,
            max_tokens=500
        )
        final_response_text = response.choices[0].message.content
        print(f"\n--- [GPT-4o-mini ì‘ë‹µ] ---")
        print(final_response_text)

        final_response = final_response_text + common_disclaimer
        
    except Exception as e:
        print(f"ë””ë²„ê·¸: ì‘ë‹µ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ - {e}")
        final_response = "ê¸°ìƒ ì •ë³´ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë„ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."

    return {**state, "response": final_response}