from chatbot.graph.state import ChatState

from chatbot.rag.utils import get_query_embedding, perform_vector_search, close_mongo_client
from chatbot.rag.config import RAG_SEARCH_CONFIG, common_llm_rag_caller
from chatbot.rag.transfer_route_helper import _parse_transfer_route_query_with_llm

def transfer_info_handler(state: ChatState) -> ChatState:
    """
    'transfer_info' ì˜ë„ì— ëŒ€í•œ RAG ê¸°ë°˜ í•¸ë“¤ëŸ¬.
    ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ MongoDBì—ì„œ í™˜ìŠ¹ ê´€ë ¨ ì¼ë°˜ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³  ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.
    ì—¬ëŸ¬ í™˜ìŠ¹ ì£¼ì œì— ëŒ€í•œ ë³µí•© ì§ˆë¬¸ë„ ì²˜ë¦¬í•  ìˆ˜ ìˆë„ë¡ ê°œì„ ë˜ì—ˆìŠµë‹ˆë‹¤.
    """
    # ğŸ“Œ ìˆ˜ì •ëœ ë¶€ë¶„: rephrased_queryë¥¼ ë¨¼ì € í™•ì¸í•˜ê³ , ì—†ìœ¼ë©´ user_inputì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
    query_to_process = state.get("rephrased_query") or state.get("user_input", "")
    intent_name = state.get("intent", "transfer_info")
    slots = state.get("slots", [])

    if not query_to_process:
        print("ë””ë²„ê·¸: ì‚¬ìš©ì ì¿¼ë¦¬ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
        return {**state, "response": "ì£„ì†¡í•©ë‹ˆë‹¤. ì§ˆë¬¸ ë‚´ìš©ì„ íŒŒì•…í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”."}

    print(f"\n--- {intent_name.upper()} í•¸ë“¤ëŸ¬ ì‹¤í–‰ ---")
    print(f"ë””ë²„ê·¸: í•¸ë“¤ëŸ¬ê°€ ì²˜ë¦¬í•  ìµœì¢… ì¿¼ë¦¬ - '{query_to_process}'")

    # ğŸš€ ìµœì í™”: slot ì •ë³´ ìš°ì„  í™œìš©, ì—†ìœ¼ë©´ LLM fallback
    # ìŠ¬ë¡¯ì—ì„œ í™˜ìŠ¹ ê´€ë ¨ í‚¤ì›Œë“œë¥¼ ëª¨ë‘ ì¶”ì¶œí•©ë‹ˆë‹¤.
    transfer_topics = [word for word, slot in slots if slot in ['B-transfer_topic', 'I-transfer_topic']]
    transport_types = [word for word, slot in slots if slot in ['B-transport_type', 'I-transport_type']]
    location_keywords = [word for word, slot in slots if slot in ['B-location', 'I-location', 'B-terminal', 'I-terminal']]
    
    search_keywords = []
    if transfer_topics or transport_types or location_keywords:
        print(f"ë””ë²„ê·¸: âš¡ slotì—ì„œ í™˜ìŠ¹ ì •ë³´ ì¶”ì¶œ - ì£¼ì œ:{transfer_topics}, êµí†µ:{transport_types}, ìœ„ì¹˜:{location_keywords}")
        
        # slot ì¡°í•©ìœ¼ë¡œ êµ¬ì²´ì ì¸ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
        all_keywords = transfer_topics + transport_types + location_keywords
        search_keywords = list(set(all_keywords)) if all_keywords else [query_to_process]
        print(f"ë””ë²„ê·¸: âš¡ slot ê¸°ë°˜ ê²€ìƒ‰ í‚¤ì›Œë“œ: {search_keywords}")
    else:
        print("ë””ë²„ê·¸: slotì— í™˜ìŠ¹ ì •ë³´ ì—†ìŒ, LLMìœ¼ë¡œ fallback")
        search_keywords = [query_to_process]

    # RAG_SEARCH_CONFIGì—ì„œ í˜„ì¬ ì˜ë„ì— ë§ëŠ” ì„¤ì • ê°€ì ¸ì˜¤ê¸°
    rag_config = RAG_SEARCH_CONFIG.get(intent_name, {})
    collection_name = rag_config.get("collection_name")
    vector_index_name = rag_config.get("vector_index_name")
    intent_description = rag_config.get("description", intent_name)
    query_filter = rag_config.get("query_filter")

    if not (collection_name and vector_index_name):
        error_msg = f"ì£„ì†¡í•©ë‹ˆë‹¤. '{intent_name}' ì˜ë„ì— ëŒ€í•œ ì •ë³´ ê²€ìƒ‰ ì„¤ì •ì„ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ ì¸ë±ìŠ¤ ì´ë¦„ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤."
        print(f"ë””ë²„ê·¸: {error_msg}")
        return {**state, "response": error_msg}

    all_retrieved_docs_text = []
    try:
        for keyword in search_keywords:
            print(f"ë””ë²„ê·¸: '{keyword}'ì— ëŒ€í•´ ê²€ìƒ‰ ì‹œì‘...")

            # ğŸ“Œ ìˆ˜ì •ëœ ë¶€ë¶„: ê²€ìƒ‰ì„ ìœ„í•´ query_embeddingì— keywordë¥¼ ì „ë‹¬í•©ë‹ˆë‹¤.
            query_embedding = get_query_embedding(keyword)
            retrieved_docs_text = perform_vector_search(
                query_embedding,
                collection_name=collection_name,
                vector_index_name=vector_index_name,
                query_filter=query_filter,
                top_k=5
            )
            all_retrieved_docs_text.extend(retrieved_docs_text)

        print(f"ë””ë²„ê·¸: MongoDBì—ì„œ ì´ {len(all_retrieved_docs_text)}ê°œ ë¬¸ì„œ ê²€ìƒ‰ ì™„ë£Œ.")
        
        if not all_retrieved_docs_text:
            return {**state, "response": "ì£„ì†¡í•©ë‹ˆë‹¤. ìš”ì²­í•˜ì‹  í™˜ìŠ¹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}

        # 3. ê²€ìƒ‰ëœ ë¬¸ì„œ ë‚´ìš©ì„ LLMì— ì „ë‹¬í•  ì»¨í…ìŠ¤íŠ¸ë¡œ ê²°í•©
        context_for_llm = "\n\n".join(all_retrieved_docs_text)
        print(f"ë””ë²„ê·¸: LLMì— ì „ë‹¬ë  ìµœì¢… ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´: {len(context_for_llm)}ì.")
        
        # 4. ê³µí†µ LLM í˜¸ì¶œ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ìµœì¢… ë‹µë³€ ìƒì„±
        # ğŸ“Œ ìˆ˜ì •ëœ ë¶€ë¶„: common_llm_rag_callerì— query_to_processë¥¼ ì „ë‹¬í•©ë‹ˆë‹¤.
        final_response = common_llm_rag_caller(query_to_process, context_for_llm, intent_description, intent_name)

        return {**state, "response": final_response}

    except Exception as e:
        error_msg = f"ì£„ì†¡í•©ë‹ˆë‹¤. ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
        print(f"ë””ë²„ê·¸: {error_msg}")
        return {**state, "response": error_msg}

def transfer_route_guide_handler(state: ChatState) -> ChatState:
    """
    'transfer_route_guide' ì˜ë„ì— ëŒ€í•œ RAG ê¸°ë°˜ í•¸ë“¤ëŸ¬.
    ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ TransitPathVectorì™€ ConnectionTimeVectorì—ì„œ í™˜ìŠ¹ ê²½ë¡œ ë° ìµœì € í™˜ìŠ¹ ì‹œê°„ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³  ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.
    ë³µí•© ì§ˆë¬¸(ì—¬ëŸ¬ ì¶œë°œì§€-ë„ì°©ì§€ ìŒ)ë„ ì²˜ë¦¬í•  ìˆ˜ ìˆë„ë¡ ê°œì„ ë˜ì—ˆìŠµë‹ˆë‹¤.
    """
    # ğŸ“Œ ìˆ˜ì •ëœ ë¶€ë¶„: rephrased_queryë¥¼ ë¨¼ì € í™•ì¸í•˜ê³ , ì—†ìœ¼ë©´ user_inputì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
    query_to_process = state.get("rephrased_query") or state.get("user_input", "")
    intent_name = state.get("intent", "transfer_route_guide")

    if not query_to_process:
        print("ë””ë²„ê·¸: ì‚¬ìš©ì ì¿¼ë¦¬ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
        return {**state, "response": "ì£„ì†¡í•©ë‹ˆë‹¤. ì§ˆë¬¸ ë‚´ìš©ì„ íŒŒì•…í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”."}

    print(f"\n--- {intent_name.upper()} í•¸ë“¤ëŸ¬ ì‹¤í–‰ ---")
    print(f"ë””ë²„ê·¸: í•¸ë“¤ëŸ¬ê°€ ì²˜ë¦¬í•  ìµœì¢… ì¿¼ë¦¬ - '{query_to_process}'")

    # â­ LLMìœ¼ë¡œ ë³µí•© ì§ˆë¬¸ì„ ë¶„í•´í•©ë‹ˆë‹¤.
    # ğŸ“Œ ìˆ˜ì •ëœ ë¶€ë¶„: _parse_transfer_route_query_with_llm í•¨ìˆ˜ì— ì¬êµ¬ì„±ëœ ì¿¼ë¦¬ë¥¼ ì „ë‹¬í•©ë‹ˆë‹¤.
    parsed_queries = _parse_transfer_route_query_with_llm(query_to_process)

    search_queries = []
    if parsed_queries and parsed_queries.get("requests"):
        search_queries = [req.get("query") for req in parsed_queries["requests"]]
    
    if not search_queries:
        # ğŸ“Œ ìˆ˜ì •ëœ ë¶€ë¶„: ë³µí•© ì§ˆë¬¸ìœ¼ë¡œ íŒŒì•…ë˜ì§€ ì•Šìœ¼ë©´, ì¬êµ¬ì„±ëœ ì¿¼ë¦¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
        search_queries = [query_to_process]
        print("ë””ë²„ê·¸: ë³µí•© ì§ˆë¬¸ìœ¼ë¡œ íŒŒì•…ë˜ì§€ ì•Šì•„ ìµœì¢… ì¿¼ë¦¬ë¡œ ê²€ìƒ‰ì„ ì‹œë„í•©ë‹ˆë‹¤.")

    rag_config = RAG_SEARCH_CONFIG.get(intent_name, {})
    main_collection_info = rag_config.get("main_collection", {})
    additional_collections_info = rag_config.get("additional_collections", [])
    intent_description = rag_config.get("description", intent_name)
    query_filter = rag_config.get("query_filter")

    if not (main_collection_info.get("name") and main_collection_info.get("vector_index")):
        error_msg = f"ì£„ì†¡í•©ë‹ˆë‹¤. '{intent_name}' ì˜ë„ì— ëŒ€í•œ ë©”ì¸ ì»¬ë ‰ì…˜ ì„¤ì •(ì´ë¦„ ë˜ëŠ” ì¸ë±ìŠ¤)ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤."
        print(f"ë””ë²„ê·¸: {error_msg}")
        return {**state, "response": error_msg}

    all_retrieved_docs_text = []
    try:
        # â­ ë¶„í•´ëœ ê° ì§ˆë¬¸ì— ëŒ€í•´ RAG ê²€ìƒ‰ì„ ê°œë³„ì ìœ¼ë¡œ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        for query in search_queries:
            print(f"ë””ë²„ê·¸: '{query}'ì— ëŒ€í•´ ê²€ìƒ‰ ì‹œì‘...")
            
            # ğŸ“Œ ìˆ˜ì •ëœ ë¶€ë¶„: ê²€ìƒ‰ì„ ìœ„í•´ query_embeddingì— queryë¥¼ ì „ë‹¬í•©ë‹ˆë‹¤.
            query_embedding = get_query_embedding(query)
            print(f"ë””ë²„ê·¸: '{query}' ì¿¼ë¦¬ ì„ë² ë”© ì™„ë£Œ.")

            # ë©”ì¸ ì»¬ë ‰ì…˜ì—ì„œ ë²¡í„° ê²€ìƒ‰
            main_collection_name = main_collection_info["name"]
            main_vector_index = main_collection_info["vector_index"]
            main_docs_text = perform_vector_search(
                query_embedding,
                collection_name=main_collection_name,
                vector_index_name=main_vector_index,
                query_filter=query_filter,
                top_k=3
            )
            all_retrieved_docs_text.extend(main_docs_text)
            
            # ì¶”ê°€ ì»¬ë ‰ì…˜ë“¤ì—ì„œ ë²¡í„° ê²€ìƒ‰
            for col_info in additional_collections_info:
                col_name = col_info.get("name")
                col_vector_index = col_info.get("vector_index")
                if col_name and col_vector_index:
                    additional_docs_text = perform_vector_search(
                        query_embedding,
                        collection_name=col_name,
                        vector_index_name=col_vector_index,
                        query_filter=query_filter,
                        top_k=2
                    )
                    all_retrieved_docs_text.extend(additional_docs_text)

        if not all_retrieved_docs_text:
            print("ë””ë²„ê·¸: ê²€ìƒ‰ëœ ê´€ë ¨ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
            return {**state, "response": "ì£„ì†¡í•©ë‹ˆë‹¤. ìš”ì²­í•˜ì‹  í™˜ìŠ¹ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}

        context_for_llm = "\n\n".join(all_retrieved_docs_text)
        print(f"ë””ë²„ê·¸: LLMì— ì „ë‹¬ë  ìµœì¢… ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´: {len(context_for_llm)}ì.")
        # ğŸ“Œ ìˆ˜ì •ëœ ë¶€ë¶„: common_llm_rag_callerì— query_to_processë¥¼ ì „ë‹¬í•©ë‹ˆë‹¤.
        final_response = common_llm_rag_caller(query_to_process, context_for_llm, intent_description, intent_name)

        return {**state, "response": final_response}

    except Exception as e:
        error_msg = f"ì£„ì†¡í•©ë‹ˆë‹¤. ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
        print(f"ë””ë²„ê·¸: {error_msg}")
        return {**state, "response": error_msg}