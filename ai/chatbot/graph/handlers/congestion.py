import os
from datetime import datetime, timedelta
import re
from chatbot.graph.state import ChatState
from dotenv import load_dotenv
from chatbot.rag.config import RAG_SEARCH_CONFIG, common_llm_rag_caller
from chatbot.rag.airport_congestion_helpers import _get_congestion_level, VALID_AREAS, _parse_query_with_llm, _get_congestion_data_from_db, _get_daily_congestion_data_from_db, _map_area_to_db_key
import json

load_dotenv()

def airport_congestion_prediction_handler(state: ChatState) -> ChatState:
    """
    ê³µí•­ í˜¼ì¡ë„ ì˜ˆì¸¡ ì •ë³´ë¥¼ MongoDBì—ì„œ ì¡°íšŒí•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” í•¸ë“¤ëŸ¬ì…ë‹ˆë‹¤.
    """
    print(f"\n--- ê³µí•­ í˜¼ì¡ë„ ì˜ˆì¸¡ í•¸ë“¤ëŸ¬ ì‹¤í–‰ ---")
    
    query_to_process = state.get("rephrased_query") or state.get("user_input", "")
    
    if not query_to_process:
        response_text = "ì£„ì†¡í•©ë‹ˆë‹¤. ì§ˆë¬¸ ë‚´ìš©ì„ íŒŒì•…í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”."
        return {**state, "response": response_text}
    
    parsed_query = _parse_query_with_llm(query_to_process)

    if parsed_query is None:
        response_text = "ì£„ì†¡í•©ë‹ˆë‹¤. ìš”ì²­ì„ ì²˜ë¦¬í•˜ëŠ” ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."
        return {**state, "response": response_text}
    
    requests_list = parsed_query.get("requests", [])
    
    # ğŸ“Œ ìˆ˜ì •ëœ ë¶€ë¶„: ìš”ì²­ ë¦¬ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆê±°ë‚˜, í„°ë¯¸ë„ ì •ë³´ê°€ ì—†ëŠ” ê²½ìš°ë¥¼ ëª¨ë‘ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    if not requests_list or (requests_list[0].get("terminal") is None and requests_list[0].get("area") is None):
        print("ë””ë²„ê·¸: í„°ë¯¸ë„ ì •ë³´ê°€ ì—†ì–´ ì „ì²´ í„°ë¯¸ë„ í˜¼ì¡ë„ ê²€ìƒ‰ì„ ì‹œë„í•©ë‹ˆë‹¤.")
        requests_list = [{"terminal": 1, "area": None}, {"terminal": 2, "area": None}]
        
    date_type = requests_list[0].get("date")
    # ... (ë‚ ì§œ ì²˜ë¦¬ ë¡œì§ì€ ë™ì¼) ...

    target_date = datetime.now().date()
    date_label = "ì˜¤ëŠ˜"
    
    response_parts_data = []
    
    try:
        hourly_data = _get_congestion_data_from_db(target_date.strftime("%Y%m%d"), datetime.now().hour)
        if not hourly_data:
            return {**state, "response": f"ì£„ì†¡í•©ë‹ˆë‹¤. {date_label} í˜„ì¬ ì‹œê°ì— ëŒ€í•œ í˜¼ì¡ë„ ì˜ˆì¸¡ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
            
        for request in requests_list:
            terminal_number = request.get("terminal")
            area_name = request.get("area")
            
            is_daily = request.get("is_daily", False) or (request.get("time") == "í•©ê³„")
            
            if is_daily:
                daily_data = _get_daily_congestion_data_from_db()
                if daily_data:
                    if terminal_number == 1:
                        response_parts_data.append({"í„°ë¯¸ë„": 1, "ìœ í˜•": "í•˜ë£¨ ì „ì²´", "ìŠ¹ê°ìˆ˜": daily_data.get("t1_arrival_sum", 0.0) + daily_data.get("t1_departure_sum", 0.0)})
                    elif terminal_number == 2:
                        response_parts_data.append({"í„°ë¯¸ë„": 2, "ìœ í˜•": "í•˜ë£¨ ì „ì²´", "ìŠ¹ê°ìˆ˜": daily_data.get("t2_arrival_sum", 0.0) + daily_data.get("t2_departure_sum", 0.0)})
            else:
                if terminal_number is not None and area_name is not None:
                    mapped_key = _map_area_to_db_key(terminal_number, area_name)
                    if mapped_key:
                        response_parts_data.append({"í„°ë¯¸ë„": terminal_number, "êµ¬ì—­": area_name, "ì‹œê°„": datetime.now().hour, "ìŠ¹ê°ìˆ˜": hourly_data.get(mapped_key, 0.0)})
                
                elif terminal_number is not None and area_name is None:
                    if terminal_number == 1:
                        total_count = float(hourly_data.get("t1_arrival_sum", 0.0)) + float(hourly_data.get("t1_departure_sum", 0.0))
                        congestion = _get_congestion_level(1, total_count)
                        response_parts_data.append({"í„°ë¯¸ë„": 1, "ìœ í˜•": "ì‹œê°„ëŒ€ë³„", "ì‹œê°„": datetime.now().hour, "ìŠ¹ê°ìˆ˜": total_count, "í˜¼ì¡ë„": congestion})
                    elif terminal_number == 2:
                        total_count = float(hourly_data.get("t2_arrival_sum", 0.0)) + float(hourly_data.get("t2_departure_sum", 0.0))
                        congestion = _get_congestion_level(2, total_count)
                        response_parts_data.append({"í„°ë¯¸ë„": 2, "ìœ í˜•": "ì‹œê°„ëŒ€ë³„", "ì‹œê°„": datetime.now().hour, "ìŠ¹ê°ìˆ˜": total_count, "í˜¼ì¡ë„": congestion})
        
        context_for_llm = json.dumps(response_parts_data, ensure_ascii=False, indent=2)

        if not response_parts_data:
            final_response_text = "ì£„ì†¡í•©ë‹ˆë‹¤. ìš”ì²­í•˜ì‹  í˜¼ì¡ë„ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        else:
            final_response_text = common_llm_rag_caller(query_to_process, context_for_llm, "ê³µí•­ í˜¼ì¡ë„ ì˜ˆì¸¡ ì •ë³´", "airport_congestion_prediction")

    except Exception as e:
        print(f"ë””ë²„ê·¸: ì‘ë‹µ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ - {e}")
        final_response_text = "í˜¼ì¡ë„ ì •ë³´ë¥¼ ì²˜ë¦¬í•˜ëŠ” ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
    
    return {**state, "response": final_response_text}