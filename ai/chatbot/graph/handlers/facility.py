from typing import List, Dict, Any
from chatbot.graph.state import ChatState
from chatbot.rag.utils import get_query_embedding, perform_vector_search, close_mongo_client
from chatbot.rag.config import RAG_SEARCH_CONFIG, common_llm_rag_caller
from chatbot.rag.llm_tools import extract_location_with_llm, _extract_facility_names_with_llm, _filter_and_rerank_docs

def _combine_individual_responses(responses: List[str]) -> str:
    """ê°œë³„ RAG í•¸ë“¤ëŸ¬ì˜ ì‘ë‹µì„ í•˜ë‚˜ë¡œ í•©ì¹˜ëŠ” í—¬í¼ í•¨ìˆ˜"""
    if not responses:
        return "ì£„ì†¡í•©ë‹ˆë‹¤. ìš”ì²­í•˜ì‹  ì‹œì„¤ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    # ì‘ë‹µì´ í•˜ë‚˜ì¼ ê²½ìš°
    if len(responses) == 1:
        return responses[0]

    # ë³µìˆ˜ì¼ ê²½ìš° ë²ˆí˜¸ë¥¼ ë¶™ì—¬ ê²°í•©
    combined_text = "ì‚¬ìš©ìë‹˜ì˜ ì—¬ëŸ¬ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì…ë‹ˆë‹¤.\n\n"
    for idx, response in enumerate(responses, 1):
        combined_text += f"{idx}. {response}\n"
    return combined_text

def facility_guide_handler(state: ChatState) -> ChatState:
    """
    'facility_guide' ì˜ë„ì— ëŒ€í•œ RAG ê¸°ë°˜ í•¸ë“¤ëŸ¬.
    ê° ì‹œì„¤ë³„ë¡œ RAGë¥¼ ê°œë³„ì ìœ¼ë¡œ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ë¥¼ í•©ì¹©ë‹ˆë‹¤.
    """
    query_to_process = state.get("rephrased_query") or state.get("user_input", "")
    intent_name = state.get("intent", "facility_guide")

    if not query_to_process:
        print("ë””ë²„ê·¸: ì‚¬ìš©ì ì¿¼ë¦¬ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
        return {**state, "response": "ì£„ì†¡í•©ë‹ˆë‹¤. ì§ˆë¬¸ ë‚´ìš©ì„ íŒŒì•…í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”."}

    print(f"\n--- {intent_name.upper()} í•¸ë“¤ëŸ¬ ì‹¤í–‰ ---")
    print(f"ë””ë²„ê·¸: í•¸ë“¤ëŸ¬ê°€ ì²˜ë¦¬í•  ìµœì¢… ì¿¼ë¦¬ - '{query_to_process}'")

    # ğŸš€ ìµœì í™”: slot ì •ë³´ ìš°ì„  í™œìš©, ì—†ìœ¼ë©´ LLM fallback
    slots = state.get("slots", [])
    
    # Terminal/ìœ„ì¹˜ ì •ë³´ ì¶”ì¶œ
    terminal_slots = [word for word, slot in slots if slot in ['B-terminal', 'I-terminal']]
    area_slots = [word for word, slot in slots if slot in ['B-area', 'I-area']]
    location_keyword = None
    
    if terminal_slots:
        location_keyword = terminal_slots[0]
        print(f"ë””ë²„ê·¸: âš¡ slotì—ì„œ í„°ë¯¸ë„ ì •ë³´ ì¶”ì¶œ: {location_keyword}")
    elif area_slots:
        location_keyword = area_slots[0]
        print(f"ë””ë²„ê·¸: âš¡ slotì—ì„œ êµ¬ì—­ ì •ë³´ ì¶”ì¶œ: {location_keyword}")
    else:
        print("ë””ë²„ê·¸: slotì— ìœ„ì¹˜ ì •ë³´ ì—†ìŒ, LLMìœ¼ë¡œ fallback")
        location_keyword = extract_location_with_llm(query_to_process)
        print(f"ë””ë²„ê·¸: LLMìœ¼ë¡œ ì¶”ì¶œëœ ìœ„ì¹˜ ì •ë³´ - {location_keyword}")
    
    # ì‹œì„¤ëª… ì •ë³´ ì¶”ì¶œ
    facility_slots = [word for word, slot in slots if slot in ['B-facility_name', 'I-facility_name']]
    
    if facility_slots:
        facility_names = facility_slots
        print(f"ë””ë²„ê·¸: âš¡ slotì—ì„œ ì‹œì„¤ëª… ì¶”ì¶œ ì™„ë£Œ (LLM í˜¸ì¶œ ìƒëµ): {facility_names}")
    else:
        print("ë””ë²„ê·¸: slotì— ì‹œì„¤ëª… ì •ë³´ ì—†ìŒ, LLMìœ¼ë¡œ fallback")
        facility_names = _extract_facility_names_with_llm(query_to_process)
        print(f"ë””ë²„ê·¸: LLMì„ ì‚¬ìš©í•´ ì¶”ì¶œëœ ì‹œì„¤ ëª©ë¡ - {facility_names}")

    if not facility_names:
        return {**state, "response": "ì£„ì†¡í•©ë‹ˆë‹¤. ìš”ì²­í•˜ì‹  ì‹œì„¤ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
    
    rag_config = RAG_SEARCH_CONFIG.get(intent_name, {})
    collection_name = rag_config.get("collection_name")
    vector_index_name = rag_config.get("vector_index_name")
    intent_description = rag_config.get("description", intent_name)
    
    # query_filterëŠ” ë” ì´ìƒ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
    # query_filter = rag_config.get("query_filter")

    if not (collection_name and vector_index_name):
        error_msg = f"ì£„ì†¡í•©ë‹ˆë‹¤. '{intent_name}' ì˜ë„ì— ëŒ€í•œ ì •ë³´ ê²€ìƒ‰ ì„¤ì •ì„ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ ì¸ë±ìŠ¤ ì´ë¦„ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤."
        print(f"ë””ë²„ê·¸: {error_msg}")
        return {**state, "response": error_msg}

    individual_responses = []
    try:
        for facility_name in facility_names:
            print(f"ë””ë²„ê·¸: '{facility_name}'ì— ëŒ€í•œ RAG íŒŒì´í”„ë¼ì¸ ì‹œì‘...")
            
            # 1ë‹¨ê³„: ë„“ì€ ë²¡í„° ê²€ìƒ‰ (í•„í„° ì—†ì´)
            query_embedding = get_query_embedding(facility_name)
            retrieved_docs_text = perform_vector_search(
                query_embedding,
                collection_name=collection_name,
                vector_index_name=vector_index_name,
                query_filter={}, # ë¹ˆ ë”•ì…”ë„ˆë¦¬ë¥¼ ì „ë‹¬í•˜ì—¬ í•„í„°ë§ì„ í•˜ì§€ ì•ŠìŒ
                top_k=10
            )
            print(f"ë””ë²„ê·¸: '{facility_name}'ì— ëŒ€í•´ {len(retrieved_docs_text)}ê°œ ë¬¸ì„œ ê²€ìƒ‰ ì™„ë£Œ.")

            # ğŸ“Œ 2ë‹¨ê³„: íŒŒì´ì¬ì—ì„œ ì§ì ‘ í•„í„°ë§
            filtered_docs = []
            if location_keyword:
                # ğŸ“Œ ìˆ˜ì •ëœ ë¡œì§: ìœ„ì¹˜ í‚¤ì›Œë“œì— ëŒ€í•œ ë‹¤ì–‘í•œ ë³€í˜•ì„ ê³ ë ¤
                # location_variants ë¦¬ìŠ¤íŠ¸ì— í‚¤ì›Œë“œë¥¼ ì¶”ê°€í•˜ì—¬ ìœ ì—°í•˜ê²Œ í•„í„°ë§
                location_variants = []
                if "1í„°ë¯¸ë„" in location_keyword or "ì œ1" in location_keyword or "t1" in location_keyword.lower():
                    location_variants = ["ì œ1ì—¬ê°í„°ë¯¸ë„", "1í„°ë¯¸ë„", "T1", "1ì—¬ê°í„°ë¯¸ë„", "1 í„°ë¯¸ë„", "ì œ1 í„°ë¯¸ë„", "ì¼í„°ë¯¸ë„", "ì¼ í„°ë¯¸ë„"]
                elif "2í„°ë¯¸ë„" in location_keyword or "ì œ2" in location_keyword or "t2" in location_keyword.lower():
                    location_variants = ["ì œ2ì—¬ê°í„°ë¯¸ë„", "2í„°ë¯¸ë„", "T2", "2ì—¬ê°í„°ë¯¸ë„", "2 í„°ë¯¸ë„", "ì œ2 í„°ë¯¸ë„", "ì´í„°ë¯¸ë„", "ì´ í„°ë¯¸ë„"]
                elif "íƒ‘ìŠ¹ë™" in location_keyword:
                    location_variants = ["íƒ‘ìŠ¹ë™"]
                
                # ë¬¸ì„œê°€ location_variants ì¤‘ í•˜ë‚˜ë¼ë„ í¬í•¨í•˜ë©´ ìœ íš¨í•˜ë‹¤ê³  íŒë‹¨
                for doc in retrieved_docs_text:
                    if any(variant in doc for variant in location_variants):
                        filtered_docs.append(doc)
                print(f"ë””ë²„ê·¸: '{facility_name}'ì— ëŒ€í•´ ìœ„ì¹˜ í•„í„°ë§ í›„ {len(filtered_docs)}ê°œ ë¬¸ì„œ ë‚¨ìŒ.")
            else:
                filtered_docs = retrieved_docs_text

            final_context = "\n\n".join(filtered_docs)

            # 3ë‹¨ê³„: ìµœì¢… LLM ë‹µë³€ ìƒì„±
            if final_context:
                truncated_docs_list = final_context.split('\n\n')[:5]
                final_context_truncated = "\n\n".join(truncated_docs_list)
                
                final_response_text = common_llm_rag_caller(
                    query_to_process,
                    final_context_truncated,
                    intent_description,
                    intent_name
                )
                individual_responses.append(final_response_text)
            else:
                individual_responses.append(f"ì£„ì†¡í•©ë‹ˆë‹¤. ìš”ì²­í•˜ì‹  '{location_keyword}' '{facility_name}' ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    except Exception as e:
        error_msg = f"ì£„ì†¡í•©ë‹ˆë‹¤. ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
        print(f"ë””ë²„ê·¸: {error_msg}")
        return {**state, "response": error_msg}
    finally:
        close_mongo_client()

    final_response = _combine_individual_responses(individual_responses)
    return {**state, "response": final_response}